{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PROCESO ETL (Extracción, Transformación y Carga de Datos) - siniestros viales"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En este proyecto, nos embarcamos en la tarea crucial de abordar y mitigar los siniestros viales que afectan a la ciudad de Buenos Aires, Argentina. Con el objetivo principal de reducir las tragedias en las vías urbanas, nos sumergiremos en el análisis de datos relacionados con incidentes viales.\n",
    "\n",
    "Nuestra misión es transformar datos crudos en conocimientos significativos que permitan comprender a fondo los patrones y factores subyacentes que contribuyen a los accidentes de tráfico. A través de un proceso ETL (Extract, Transform, Load), daremos forma a conjuntos de datos dispersos para obtener información valiosa.\n",
    "\n",
    "El propósito último es proporcionar a las autoridades, organizaciones de tráfico y ciudadanos en general una visión clara y detallada de las áreas de mayor riesgo, los momentos críticos y los elementos que más influyen en la seguridad vial. Con esta información, se pretende impulsar la implementación de medidas preventivas y estrategias eficaces que contribuyan a la reducción significativa de las tragedias viales en la Ciudad Autónoma de Buenos Aires."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importamos BIBLIOTECAS necesarias para nuestros primeros pasos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CARGA DE LOS DATOS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creamos una __FUNCION__ para cargar los archivos.\n",
    "Carga datos desde un archivo Excel y devuelve un diccionario de DataFrames.\n",
    "\n",
    "    Parameters:\n",
    "    - archivo (str): Ruta del archivo Excel.\n",
    "    - hojas (list): Lista de nombres de hojas a cargar.\n",
    "    - engine (str, optional): Motor de Excel a utilizar. Por defecto, 'openpyxl'.\n",
    "\n",
    "    Returns:\n",
    "    dfs: Un diccionario donde las claves son los nombres de las hojas y los valores son DataFrames correspondientes.\n",
    "\n",
    "    Example:\n",
    "    >>> datos = cargar_datos_desde_excel('archivo.xlsx', ['Hoja1', 'Hoja2'])\n",
    "    >>> df_hoja1 = datos['Hoja1']\n",
    "    >>> df_hoja2 = datos['Hoja2']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cargar_datos_desde_excel(archivo, hojas, engine='openpyxl'):    \n",
    "    xls_file = pd.ExcelFile(archivo, engine=engine)\n",
    "    dfs = {}\n",
    "\n",
    "    for hoja in hojas:\n",
    "        df = pd.read_excel(xls_file, hoja) \n",
    "        dfs[hoja] = df\n",
    "\n",
    "    return dfs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "datos_homicidios = cargar_datos_desde_excel('homicidios.xlsx', ['HECHOS', 'VICTIMAS'])\n",
    "datos_homicidios = cargar_datos_desde_excel('lesiones.xlsx', ['HECHOS', 'VICTIMAS'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### EXPLORACION Y LIMPIEZA DE LOS DATOS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__DataSet:__ HOMICIOS - HECHOS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Accedemos al dataframe por nombre de hoja, homicidios - hechos\n",
    "\n",
    "h_h_df = datos_homicidios ['HECHOS']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataFrame ORIGIANAL:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>n_victimas</th>\n",
       "      <th>aaaa</th>\n",
       "      <th>mm</th>\n",
       "      <th>dd</th>\n",
       "      <th>fecha</th>\n",
       "      <th>hora</th>\n",
       "      <th>franja_hora</th>\n",
       "      <th>direccion_normalizada</th>\n",
       "      <th>comuna</th>\n",
       "      <th>...</th>\n",
       "      <th>latutid</th>\n",
       "      <th>victima</th>\n",
       "      <th>acusado</th>\n",
       "      <th>participantes</th>\n",
       "      <th>moto</th>\n",
       "      <th>auto</th>\n",
       "      <th>transporte_publico</th>\n",
       "      <th>camion</th>\n",
       "      <th>ciclista</th>\n",
       "      <th>gravedad</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LC-2019-0000179</td>\n",
       "      <td>1</td>\n",
       "      <td>2019</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2019-01-01 00:00:00</td>\n",
       "      <td>09:00:00</td>\n",
       "      <td>9</td>\n",
       "      <td>SD</td>\n",
       "      <td>14</td>\n",
       "      <td>...</td>\n",
       "      <td>-34.559658</td>\n",
       "      <td>CICLISTA</td>\n",
       "      <td>SD</td>\n",
       "      <td>CICLISTA-SD</td>\n",
       "      <td>SD</td>\n",
       "      <td>SD</td>\n",
       "      <td>SD</td>\n",
       "      <td>SD</td>\n",
       "      <td>x</td>\n",
       "      <td>SD</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>LC-2019-0000053</td>\n",
       "      <td>1</td>\n",
       "      <td>2019</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2019-01-01 00:00:00</td>\n",
       "      <td>01:55:00</td>\n",
       "      <td>1</td>\n",
       "      <td>SD</td>\n",
       "      <td>8</td>\n",
       "      <td>...</td>\n",
       "      <td>-34.669125</td>\n",
       "      <td>AUTO</td>\n",
       "      <td>SD</td>\n",
       "      <td>AUTO-SD</td>\n",
       "      <td>SD</td>\n",
       "      <td>x</td>\n",
       "      <td>SD</td>\n",
       "      <td>SD</td>\n",
       "      <td>SD</td>\n",
       "      <td>SD</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>LC-2019-0000063</td>\n",
       "      <td>1</td>\n",
       "      <td>2019</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2019-01-01 00:00:00</td>\n",
       "      <td>02:00:00</td>\n",
       "      <td>2</td>\n",
       "      <td>SD</td>\n",
       "      <td>8</td>\n",
       "      <td>...</td>\n",
       "      <td>-34.677556</td>\n",
       "      <td>SD</td>\n",
       "      <td>SD</td>\n",
       "      <td>SD-SD</td>\n",
       "      <td>SD</td>\n",
       "      <td>SD</td>\n",
       "      <td>SD</td>\n",
       "      <td>SD</td>\n",
       "      <td>SD</td>\n",
       "      <td>SD</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>LC-2019-0000079</td>\n",
       "      <td>1</td>\n",
       "      <td>2019</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2019-01-01 00:00:00</td>\n",
       "      <td>02:30:00</td>\n",
       "      <td>2</td>\n",
       "      <td>SD</td>\n",
       "      <td>7</td>\n",
       "      <td>...</td>\n",
       "      <td>-34.647349</td>\n",
       "      <td>PEATON</td>\n",
       "      <td>SD</td>\n",
       "      <td>PEATON-SD</td>\n",
       "      <td>x</td>\n",
       "      <td>SD</td>\n",
       "      <td>SD</td>\n",
       "      <td>SD</td>\n",
       "      <td>SD</td>\n",
       "      <td>SD</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>LC-2019-0000082</td>\n",
       "      <td>4</td>\n",
       "      <td>2019</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2019-01-01 00:00:00</td>\n",
       "      <td>04:30:00</td>\n",
       "      <td>4</td>\n",
       "      <td>SD</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>-34.604579</td>\n",
       "      <td>AUTO</td>\n",
       "      <td>SD</td>\n",
       "      <td>AUTO-SD</td>\n",
       "      <td>SD</td>\n",
       "      <td>SD</td>\n",
       "      <td>x</td>\n",
       "      <td>SD</td>\n",
       "      <td>SD</td>\n",
       "      <td>SD</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 27 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                id  n_victimas  aaaa  mm  dd                fecha      hora  \\\n",
       "0  LC-2019-0000179           1  2019   1   1  2019-01-01 00:00:00  09:00:00   \n",
       "1  LC-2019-0000053           1  2019   1   1  2019-01-01 00:00:00  01:55:00   \n",
       "2  LC-2019-0000063           1  2019   1   1  2019-01-01 00:00:00  02:00:00   \n",
       "3  LC-2019-0000079           1  2019   1   1  2019-01-01 00:00:00  02:30:00   \n",
       "4  LC-2019-0000082           4  2019   1   1  2019-01-01 00:00:00  04:30:00   \n",
       "\n",
       "  franja_hora direccion_normalizada comuna  ...     latutid   victima acusado  \\\n",
       "0           9                    SD     14  ...  -34.559658  CICLISTA      SD   \n",
       "1           1                    SD      8  ...  -34.669125      AUTO      SD   \n",
       "2           2                    SD      8  ...  -34.677556        SD      SD   \n",
       "3           2                    SD      7  ...  -34.647349    PEATON      SD   \n",
       "4           4                    SD      3  ...  -34.604579      AUTO      SD   \n",
       "\n",
       "   participantes moto auto transporte_publico camion ciclista gravedad  \n",
       "0    CICLISTA-SD   SD   SD                 SD     SD        x       SD  \n",
       "1        AUTO-SD   SD    x                 SD     SD       SD       SD  \n",
       "2          SD-SD   SD   SD                 SD     SD       SD       SD  \n",
       "3      PEATON-SD    x   SD                 SD     SD       SD       SD  \n",
       "4        AUTO-SD   SD   SD                  x     SD       SD       SD  \n",
       "\n",
       "[5 rows x 27 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Visualizacion de las primeras filas del dataframe\n",
    "\n",
    "print('DataFrame ORIGIANAL:')\n",
    "h_h_df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 23785 entries, 0 to 23784\n",
      "Data columns (total 27 columns):\n",
      " #   Column                 Non-Null Count  Dtype  \n",
      "---  ------                 --------------  -----  \n",
      " 0   id                     23785 non-null  object \n",
      " 1   n_victimas             23785 non-null  int64  \n",
      " 2   aaaa                   23785 non-null  int64  \n",
      " 3   mm                     23785 non-null  int64  \n",
      " 4   dd                     23785 non-null  int64  \n",
      " 5   fecha                  23785 non-null  object \n",
      " 6   hora                   23785 non-null  object \n",
      " 7   franja_hora            23780 non-null  object \n",
      " 8   direccion_normalizada  23732 non-null  object \n",
      " 9   comuna                 23616 non-null  object \n",
      " 10  tipo_calle             23785 non-null  object \n",
      " 11  otra_direccion         23785 non-null  object \n",
      " 12  calle                  12867 non-null  object \n",
      " 13  altura                 12771 non-null  float64\n",
      " 14  cruce                  9407 non-null   object \n",
      " 15  geocodificacion_CABA   23746 non-null  object \n",
      " 16  longitud               23523 non-null  object \n",
      " 17  latutid                23523 non-null  object \n",
      " 18  victima                23785 non-null  object \n",
      " 19  acusado                23785 non-null  object \n",
      " 20  participantes          23785 non-null  object \n",
      " 21  moto                   23692 non-null  object \n",
      " 22  auto                   23692 non-null  object \n",
      " 23  transporte_publico     23692 non-null  object \n",
      " 24  camion                 23692 non-null  object \n",
      " 25  ciclista               23692 non-null  object \n",
      " 26  gravedad               23785 non-null  object \n",
      "dtypes: float64(1), int64(4), object(22)\n",
      "memory usage: 4.9+ MB\n"
     ]
    }
   ],
   "source": [
    "#Obtener informacion general del Dataframe\n",
    "\n",
    "h_h_df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tras verificar el diccionario de datos, identificamos que los valores \"SD\" corresponden a \"Sin datos\". Por consiguiente, tomamos la decisión de cambiar estos valores a NaN para estandarizar."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creamos una __FUNCION__ para Analizar los valores.\n",
    "\n",
    "Analiza la presencia de valores 'SD' en cada columna del DataFrame.\n",
    "\n",
    "    Parameters:\n",
    "    dataframe (pd.DataFrame): El DataFrame a analizar.\n",
    "\n",
    "    Returns:\n",
    "    pd.DataFrame: Un DataFrame que muestra la cantidad y porcentaje de valores 'SD' en cada columna."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def analizar_valores_sd(dataframe):\n",
    "\n",
    "    columnas_con_sd = dataframe.columns\n",
    "    resultados = []\n",
    "\n",
    "    for columna in columnas_con_sd:\n",
    "        cantidad_sd = dataframe[columna].eq('SD').sum()\n",
    "        porcentaje_sd = (cantidad_sd / len(dataframe)) * 100\n",
    "        resultados.append({'Columna': columna, 'Cantidad de SD': cantidad_sd, 'Porcentaje de SD': porcentaje_sd})\n",
    "\n",
    "    resultados_df = pd.DataFrame(resultados)\n",
    "    resultados_con_sd = resultados_df[resultados_df['Cantidad de SD'] > 0]\n",
    "\n",
    "    return resultados_con_sd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Columna</th>\n",
       "      <th>Cantidad de SD</th>\n",
       "      <th>Porcentaje de SD</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>hora</td>\n",
       "      <td>4</td>\n",
       "      <td>0.016817</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>direccion_normalizada</td>\n",
       "      <td>10815</td>\n",
       "      <td>45.469834</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>comuna</td>\n",
       "      <td>846</td>\n",
       "      <td>3.556864</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>tipo_calle</td>\n",
       "      <td>11045</td>\n",
       "      <td>46.436830</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>otra_direccion</td>\n",
       "      <td>18295</td>\n",
       "      <td>76.918226</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>geocodificacion_CABA</td>\n",
       "      <td>1213</td>\n",
       "      <td>5.099853</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>longitud</td>\n",
       "      <td>1209</td>\n",
       "      <td>5.083036</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>latutid</td>\n",
       "      <td>1209</td>\n",
       "      <td>5.083036</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>victima</td>\n",
       "      <td>10733</td>\n",
       "      <td>45.125079</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>acusado</td>\n",
       "      <td>15288</td>\n",
       "      <td>64.275804</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>moto</td>\n",
       "      <td>8511</td>\n",
       "      <td>35.783057</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>auto</td>\n",
       "      <td>12543</td>\n",
       "      <td>52.734917</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>transporte_publico</td>\n",
       "      <td>11801</td>\n",
       "      <td>49.615304</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>camion</td>\n",
       "      <td>12708</td>\n",
       "      <td>53.428631</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>ciclista</td>\n",
       "      <td>11353</td>\n",
       "      <td>47.731764</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>gravedad</td>\n",
       "      <td>23056</td>\n",
       "      <td>96.935043</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  Columna  Cantidad de SD  Porcentaje de SD\n",
       "6                    hora               4          0.016817\n",
       "8   direccion_normalizada           10815         45.469834\n",
       "9                  comuna             846          3.556864\n",
       "10             tipo_calle           11045         46.436830\n",
       "11         otra_direccion           18295         76.918226\n",
       "15   geocodificacion_CABA            1213          5.099853\n",
       "16               longitud            1209          5.083036\n",
       "17                latutid            1209          5.083036\n",
       "18                victima           10733         45.125079\n",
       "19                acusado           15288         64.275804\n",
       "21                   moto            8511         35.783057\n",
       "22                   auto           12543         52.734917\n",
       "23     transporte_publico           11801         49.615304\n",
       "24                 camion           12708         53.428631\n",
       "25               ciclista           11353         47.731764\n",
       "26               gravedad           23056         96.935043"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Llamamos la funcion analizar valores\n",
    "\n",
    "resultados_h_hechos = analizar_valores_sd(h_h_df)\n",
    "resultados_h_hechos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Remplazar SD por NaN en todo el DataFrame\n",
    "\n",
    "h_h_df.replace(['SD','sd'], np.nan, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creamos una __FUNCION__ para comenzar con el proceso de limpieza de datos en un DataFrame.\n",
    "\n",
    "    Parámetros:\n",
    "    - df (pd.DataFrame): El DataFrame que se va a limpiar.\n",
    "    \n",
    "    - drop_duplicates (bool): Elimina duplicados si es True.\n",
    "      Ejemplo: cleaned_df = data_cleaning(df_tu_data_frame, drop_duplicates=True)\n",
    "    \n",
    "    - drop_na (bool): Elimina filas con valores nulos si es True.\n",
    "      Ejemplo: cleaned_df = data_cleaning(df_tu_data_frame, drop_na=True)\n",
    "\n",
    "    - fill_na (dict): Un diccionario donde las claves son los nombres de columnas y los valores son valores para rellenar los nulos.\n",
    "      Ejemplo: fill_na_dict = {'gravedad': 'leve'}\n",
    "               cleaned_df = data_cleaning(df_tu_data_frame, fill_na=fill_na_dict)\n",
    "        \n",
    "    - convert_to_datetime (list): Lista de columnas para convertir a tipo de dato datetime.\n",
    "      Ejemplo: columns_to_convert = ['fecha', 'hora']\n",
    "               cleaned_df = data_cleaning(df_tu_data_frame, convert_to_datetime=columns_to_convert)\n",
    "\n",
    "    - uppercase_columns (list): Lista de columnas para convertir a mayúsculas.\n",
    "      Ejemplo: columns_to_uppercase = ['nombre', 'apellido']\n",
    "               cleaned_df = data_cleaning(df_tu_data_frame, uppercase_columns=columns_to_uppercase)\n",
    "\n",
    "    - lowercase_columns (list): Lista de columnas para convertir a minúsculas.\n",
    "      Ejemplo: columns_to_lowercase = ['Ciudad', 'Pais']\n",
    "               cleaned_df = data_cleaning(df_tu_data_frame, lowercase_columns=columns_to_lowercase)\n",
    "\n",
    "    - titlecase_columns (list): Lista de columnas para convertir a formato de título (primera letra en mayúscula, resto en minúscula).\n",
    "      Ejemplo: columns_to_titlecase = ['titulo', 'categoria']\n",
    "               cleaned_df = data_cleaning(df_tu_data_frame, titlecase_columns=columns_to_titlecase)\n",
    "            \n",
    "    - strip_spaces (bool): Elimina espacios en blanco alrededor de los valores de las celdas si es True.\n",
    "      Ejemplo: cleaned_df = data_cleaning(df_tu_data_frame, strip_spaces=True)\n",
    "\n",
    "    - rename_columns (dict): Un diccionario donde las claves son los nombres de las columnas actuales y los valores son los nuevos nombres.\n",
    "      Ejemplo: rename_dict = {'Vieja_Columna': 'Nueva_Columna'}\n",
    "               cleaned_df = data_cleaning(df_tu_data_frame, rename_columns=rename_dict)\n",
    "    \n",
    "    - drop_columns (list): Lista de columnas para eliminar.\n",
    "      Ejemplo: columns_to_drop = ['columna1', 'columna2']\n",
    "               cleaned_df = data_cleaning(df_tu_data_frame, drop_columns=columns_to_drop)\n",
    "        \n",
    "    - categorize_columns (list): Lista de columnas para convertir a tipo de dato categoría.\n",
    "      Ejemplo: columns_to_categorize = ['categoria1', 'categoria2']\n",
    "               cleaned_df = data_cleaning(df_tu_data_frame, categorize_columns=columns_to_categorize)\n",
    "        \n",
    "    - replace_values (dict): Un diccionario donde las claves son los nombres de las columnas y los valores son diccionarios de reemplazo.\n",
    "      Ejemplo: replace_dict = {'columna1': {'Antiguo1': 'Nuevo1', 'Antiguo2': 'Nuevo2'}}\n",
    "               cleaned_df = data_cleaning(df_tu_data_frame, replace_values=replace_dict)\n",
    "\n",
    "    - new_columns (dict): Un diccionario donde las claves son los nombres de las nuevas columnas y los valores son valores para esas columnas.\n",
    "      Ejemplo: new_columns_dict = {'nueva_columna': 0}\n",
    "               cleaned_df = data_cleaning(df_tu_data_frame, new_columns=new_columns_dict)\n",
    "               \n",
    "    - new_columns2 (dict): Un diccionario donde las claves son los nombres de las nuevas columnas y los valores son expresiones\n",
    "                          para calcular el contenido de las nuevas columnas basadas en otras columnas existentes. \n",
    "      Ejemplo: {'nueva_columna1': 'columna_existente * 2'}\n",
    "      cleaned_df = data_cleaning(df_tu_data_frame, new_columns2=new_columns_dict)\n",
    "\n",
    " \n",
    "    - convert_date_columns (dict): Un diccionario donde las claves son los nombres de las columnas y los valores son los formatos de fecha.\n",
    "      Ejemplo: date_columns_dict = {'fecha': '%Y-%m-%d', 'hora': '%H:%M:%S'}\n",
    "               cleaned_df = data_cleaning(df_tu_data_frame, convert_date_columns=date_columns_dict)\n",
    "\n",
    "    - convert_to_int_columns (list): Lista de columnas para convertir a tipo de dato entero.\n",
    "      Ejemplo: columns_to_int = ['columna1', 'columna2']\n",
    "               cleaned_df = data_cleaning(df_tu_data_frame, convert_to_int_columns=columns_to_int)\n",
    "    \n",
    "    - convert_to_float (list): Lista de columnas para convertir a tipo de dato float.\n",
    "      Ejemplo: columns_to_float = ['columna1', 'columna2']\n",
    "               cleaned_df = data_cleaning(df_tu_data_frame, convert_to_float=columns_to_float)          \n",
    "            \n",
    "    Retorna:\n",
    "    pd.DataFrame: El DataFrame limpio.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_cleaning(df, drop_duplicates=False, drop_na=False, fill_na=None, convert_to_datetime=None, uppercase_columns=None,\n",
    "                  lowercase_columns=None, titlecase_columns=None, strip_spaces=True, rename_columns=None, drop_columns=None,\n",
    "                  categorize_columns=None, replace_values=None, new_columns=None, convert_date_columns=None, \n",
    "                  convert_to_int_columns=None, convert_to_float=None, new_columns2=None):\n",
    "\n",
    "    cleaned_df = df.copy()\n",
    "\n",
    "    # Eliminar duplicados\n",
    "    if drop_duplicates:\n",
    "        cleaned_df.drop_duplicates(inplace=True)\n",
    "        \n",
    "\n",
    "    # Eliminar filas con valores nulos\n",
    "    if drop_na:\n",
    "        cleaned_df.dropna(inplace=True)\n",
    "        \n",
    "\n",
    "    # Rellenar valores nulos\n",
    "    if fill_na:\n",
    "        cleaned_df.fillna(fill_na, inplace=True)\n",
    "\n",
    "        \n",
    "    # Convertir columnas a tipo datetime\n",
    "    if convert_to_datetime:\n",
    "        for column in convert_to_datetime:\n",
    "            cleaned_df[column] = pd.to_datetime(cleaned_df[column], errors='coerce')\n",
    "            \n",
    "\n",
    "    # Convertir columnas a mayúsculas\n",
    "    if uppercase_columns:\n",
    "        for column in uppercase_columns:\n",
    "            cleaned_df[column] = cleaned_df[column].str.upper()\n",
    "            \n",
    "\n",
    "    # Convertir columnas a minúsculas\n",
    "    if lowercase_columns:\n",
    "        for column in lowercase_columns:\n",
    "            cleaned_df[column] = cleaned_df[column].str.lower()\n",
    "        \n",
    "\n",
    "    # Convertir columnas a formato de título\n",
    "    if titlecase_columns:\n",
    "        for column in titlecase_columns:\n",
    "            cleaned_df[column] = cleaned_df[column].str.title()\n",
    "            \n",
    "            \n",
    "    # Tratar columnas con espacios\n",
    "    if strip_spaces:\n",
    "        cleaned_df = cleaned_df.applymap(lambda x: x.strip() if isinstance(x, str) else x)\n",
    "        \n",
    "\n",
    "    # Renombrar columnas\n",
    "    if rename_columns:\n",
    "        cleaned_df.rename(columns=rename_columns, inplace=True)\n",
    "        \n",
    "    \n",
    "    # Eliminar columnas\n",
    "    if drop_columns:\n",
    "        cleaned_df.drop(columns=drop_columns, inplace=True)\n",
    "        \n",
    "        \n",
    "    # Categorizar columnas\n",
    "    if categorize_columns:\n",
    "        for column in categorize_columns:\n",
    "            if column in cleaned_df.columns:\n",
    "                cleaned_df[column] = cleaned_df[column].astype('category')\n",
    "            else:\n",
    "                print(f\"La columna '{column}' no existe en el DataFrame.\")\n",
    "                \n",
    "\n",
    "    # Reemplazar valores en columnas\n",
    "    if replace_values:\n",
    "        for column, replacements in replace_values.items():\n",
    "            cleaned_df[column].replace(replacements, inplace=True)\n",
    "            \n",
    "    # Agregar nuevas columnas\n",
    "    if new_columns:\n",
    "        for column, value in new_columns.items():\n",
    "            cleaned_df[column] = value\n",
    "            \n",
    "    # Agregar nuevas columnas basadas en otras columnas\n",
    "    if new_columns2:\n",
    "        for new_column, column_expr in new_columns2.items():\n",
    "            # Verificar si la expresión es proporcionada\n",
    "            if column_expr:\n",
    "                cleaned_df[new_column] = cleaned_df.eval(column_expr)\n",
    "            else:\n",
    "                cleaned_df[new_column] = None  # O cualquier valor predeterminado que prefieras\n",
    "                  \n",
    "    # Convertir columnas de fecha con formato específico\n",
    "    if convert_date_columns:\n",
    "        for column, date_format in convert_date_columns.items():\n",
    "            cleaned_df[column] = pd.to_datetime(cleaned_df[column], format=date_format, errors='coerce')\n",
    "\n",
    "    \n",
    "    # Convertir columnas a tipo de dato entero\n",
    "    if convert_to_int_columns:\n",
    "        for column in convert_to_int_columns:\n",
    "            cleaned_df[column] = pd.to_numeric(cleaned_df[column], errors='coerce').astype('Int64')\n",
    "    \n",
    "    \n",
    "    # Convertir columnas a tipo float\n",
    "    if convert_to_float:\n",
    "        for column in convert_to_float:\n",
    "            cleaned_df[column] = cleaned_df[column].astype(float)\n",
    "        \n",
    "            \n",
    "    return cleaned_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Iniciamos la preparación de los diccionarios y listas que alimentaran la función 'data_cleaning' "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Columnas para pasar a minúcula\n",
    "\n",
    "columns_to_lower = ['TIPO_DE_CALLE', 'VICTIMA', 'ACUSADO']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convertir todos los datos a minúsculas evita posibles problemas de coincidencia y simplificas las operaciones de búsqueda y filtrado."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Columnas para eliminar\n",
    "\n",
    "columns_to_drop = ['AAAA', 'MM', 'DD', 'HORA', 'LUGAR_DEL_HECHO','Calle','Altura',\n",
    "                   'Cruce','Dirección Normalizada','XY (CABA)','PARTICIPANTES']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Decidimos eliminar las columnas 'AAAA', 'MM', y 'DD' del conjunto de datos, ya que la información de fecha ya está presente en la columna 'FECHA'. Esta decisión simplifica el conjunto de datos, mantiene una estructura más consistente y estandarizada, ahorra espacio y facilita el análisis temporal.\n",
    "\n",
    "Asimismo, eliminamos la columna 'HORA' debido a la redundancia de la información de hora, que ya está contenida en la columna 'HH'. Esta elección nos proporciona una visión más general y simplificada de la distribución de los siniestros a lo largo del día.\n",
    "\n",
    "Las columnas 'LUGAR_DEL_HECHO','Calle','Altura','Cruce' y 'Dirección Normalizada' implicaban datos de la dirección del hecho incluso, 'XY (CABA)' que contenía coordenadas en formato de proyección cartesiana también fue eliminada. Preferimos trabajar con las columnas de latitud y longitud por su mayor intuición, no tiene datos nulos, familiaridad para la mayoría de las personas, facilidad de representación gráfica en mapas y conformidad con estándares de sistemas de información geográfica (SIG).\n",
    "\n",
    "La columna 'PARTICIPANTES' contenia información concatenada redundante de 'VICTIMA' y 'ACUSADO', así que se mantuvieron éstas dos últimas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Renombrar columnas\n",
    "\n",
    "rename_dict = {'ID': 'id_siniestro', 'N_VICTIMAS': 'nro_victimas', 'FECHA': 'fecha', 'HH': 'franja_hora',\n",
    "               'TIPO_DE_CALLE': 'tipo_calle', 'COMUNA': 'comuna', 'pos x': 'longitud', 'pos y': 'latitud',\n",
    "               'VICTIMA': 'vehiculo_victima', 'ACUSADO': 'vehiculo_acusado'}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Renombramos columnas para mejorar la claridad y legibilidad del conjunto de datos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convertir a entero\n",
    "\n",
    "columns_to_int = [ 'nro_victimas', 'franja_hora', 'comuna']"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
